{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import spacy.displacy as displacy #Text Visualization\n",
    "import numpy as np  # useful for many scientific computing in Python\n",
    "import pandas as pd # primary data structure library\n",
    "from geopy.geocoders import Nominatim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epub2thtml(epub_path):\n",
    "    book = epub.read_epub(epub_path)\n",
    "    chapters = []\n",
    "    for item in book.get_items():\n",
    "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            chapters.append(item.get_content())\n",
    "    return chapters\n",
    "\n",
    "blacklist = [   '[document]',   'noscript', 'header',   'html', 'meta', 'head','input', 'script', '\\n'   ]\n",
    "# there may be more elements you don't want, such as \"style\", etc.\n",
    "def chap2text(chap):\n",
    "    output = ''\n",
    "    soup = BeautifulSoup(chap, 'html.parser')\n",
    "    text = soup.find_all(text=True)\n",
    "    for t in text:\n",
    "        if t.parent.name not in blacklist:\n",
    "            output += '{} '.format(t)\n",
    "    return output\n",
    "\n",
    "def thtml2ttext(thtml):\n",
    "    Output = []\n",
    "    for html in thtml:\n",
    "        text =  chap2text(html)\n",
    "        Output.append(text)\n",
    "    return Output\n",
    "\n",
    "def epub2text(epub_path):\n",
    "    chapters = epub2thtml(epub_path)\n",
    "    ttext = thtml2ttext(chapters)\n",
    "    return ttext\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Book=\"C:\\\\Users\\\\aleja\\\\OneDrive\\\\Documents\\\\MBA\\\\99. Project Work\\\\Libros\\\\Brown, Dan - Angels & Demons.epub\"\n",
    "nlp=spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=epub2text(Book)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[170, 72467, 132418, 142038, 185929, 51376, 183713, 169416, 6]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "number_words=[]\n",
    "ff=len(out)\n",
    "print(ff)\n",
    "z=0\n",
    "for i in (out):\n",
    "    number_words.append(len(out[z]))\n",
    "    z=z+1\n",
    "number_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s):\n",
    "    # initialize an empty string \n",
    "    str1 = \" \" \n",
    "    \n",
    "    # return string   \n",
    "    return (str1.join(s)) \n",
    "    # Driver code     \n",
    "Book=(listToString(out))  \n",
    "\n",
    "Book2=nlp(Book)\n",
    "\n",
    "lugares=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[]\n",
    "lugares=[]\n",
    "start_ent=[]\n",
    "end_ent=[]\n",
    "for ent in Book2.ents:\n",
    "    #print(ent.text, ent.label_)\n",
    "    #if ent.label_==\"GPE\" or  ent.label_==\"LOC\" or  ent.label_==\"FAC\" or  ent.label_==\"PERSON\":\n",
    "    if ent.label_==\"GPE\" or  ent.label_==\"LOC\" or  ent.label_==\"FAC\":\n",
    "        lugares.append(ent.text)\n",
    "        label.append(ent.label_)\n",
    "        start_ent.append(ent.start_char)\n",
    "        end_ent.append(ent.end_char)\n",
    "\n",
    "#spacy.displacy.render(Book2, style=\"ent\", page=\"true\")\n",
    "#displacy.serve(Book2, style=\"ent\")\n",
    "\n",
    "#np.save('lugares_Diarios', lugares)"
   ]
  },
  {
   "source": [
    "len(lugares)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[192, 558, 572, 582, 592, 877, 896, 906, 916, 1065]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "start_ent[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Book[0:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_book(lugares, label, start_ent, end_ent, Book):\n",
    "    #len(start_ent)\n",
    "    start_frase=[]\n",
    "    end_frase=[]\n",
    "    for i in end_ent[::]:\n",
    "        z=i\n",
    "    \n",
    "        while z<len(Book):\n",
    "            if Book[z]==\".\":\n",
    "            #print(\"finish aqui\", z, i)\n",
    "                end_frase.append(z)\n",
    "                break\n",
    "            else:\n",
    "                z+=1\n",
    "    \n",
    "    for x in start_ent[::]:\n",
    "        f=x\n",
    "        while f>=0:\n",
    "            if Book[f]==\".\":\n",
    "            \n",
    "                start_frase.append(f)\n",
    "            #print(\"start aqui\", f,x)\n",
    "                break\n",
    "            else:\n",
    "                f-=1\n",
    "                if f<0:\n",
    "                    Null=None\n",
    "                    start_frase.append(Null)\n",
    "    Frases_Book=[]\n",
    "    z=0\n",
    "    for i in start_frase:\n",
    "        Frases_clean=re.sub('\\n |  |\\. ', '', (Book[start_frase[z]:end_frase[z]]))\n",
    "        Frases_Book.append(Frases_clean)\n",
    "        z+=1\n",
    "    \n",
    "    Data_Book=pd.DataFrame(list(zip(lugares, label, Frases_Book)), columns=[\"lugares\",\"labels\", \"Quotes\"])\n",
    "    Data_Book=pd.DataFrame(list(zip(lugares, label, Frases_Book, Data_Book.index)), columns=[\"lugares\",\"labels\",\"Quotes\", \"Position\"])\n",
    "    #Data_Book=pd.DataFrame(list(zip(Data_Book.index)), columns=[\"Position\"])\n",
    "    Data_Book.to_csv(\"Data/Data_Book.csv\")\n",
    "    print(\"Quotes extracted\")\n",
    "    return Frases_Book, Data_Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Quotes extracted\n"
     ]
    }
   ],
   "source": [
    "Frases, Data_Book=quote_book(lugares, label, start_ent, end_ent, Book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 lugares labels  \\\n",
       "0               New York    GPE   \n",
       "1                 Avenue    FAC   \n",
       "2               Americas    LOC   \n",
       "3               New York    GPE   \n",
       "4                     NY    GPE   \n",
       "...                  ...    ...   \n",
       "1019        Vatican City    GPE   \n",
       "1020             Vatican    FAC   \n",
       "1021  St. Peter’s Square    GPE   \n",
       "1022               earth    LOC   \n",
       "1023         New England    LOC   \n",
       "\n",
       "                                                 Quotes  Position  \n",
       "0     Also by Dan Brown \\nDigital FortressA N G E L ...         0  \n",
       "1     1230 Avenue of the Americas, New York, NY 1002...         1  \n",
       "2     1230 Avenue of the Americas, New York, NY 1002...         2  \n",
       "3     1230 Avenue of the Americas, New York, NY 1002...         3  \n",
       "4     1230 Avenue of the Americas, New York, NY 1002...         4  \n",
       "...                                                 ...       ...  \n",
       "1019  .”\\nLangdon felt a sudden anxiety, wondering i...      1019  \n",
       "1020   \\n“His Holiness asked me to give this to you,...      1020  \n",
       "1021  He and Vittoria had talked about it last night...      1021  \n",
       "1022  “Maybe for your nextexperiment, you could stud...      1022  \n",
       "1023              He lives in New England with his wife      1023  \n",
       "\n",
       "[1024 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lugares</th>\n      <th>labels</th>\n      <th>Quotes</th>\n      <th>Position</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>New York</td>\n      <td>GPE</td>\n      <td>Also by Dan Brown \\nDigital FortressA N G E L ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Avenue</td>\n      <td>FAC</td>\n      <td>1230 Avenue of the Americas, New York, NY 1002...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Americas</td>\n      <td>LOC</td>\n      <td>1230 Avenue of the Americas, New York, NY 1002...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New York</td>\n      <td>GPE</td>\n      <td>1230 Avenue of the Americas, New York, NY 1002...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NY</td>\n      <td>GPE</td>\n      <td>1230 Avenue of the Americas, New York, NY 1002...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1019</th>\n      <td>Vatican City</td>\n      <td>GPE</td>\n      <td>.”\\nLangdon felt a sudden anxiety, wondering i...</td>\n      <td>1019</td>\n    </tr>\n    <tr>\n      <th>1020</th>\n      <td>Vatican</td>\n      <td>FAC</td>\n      <td>\\n“His Holiness asked me to give this to you,...</td>\n      <td>1020</td>\n    </tr>\n    <tr>\n      <th>1021</th>\n      <td>St. Peter’s Square</td>\n      <td>GPE</td>\n      <td>He and Vittoria had talked about it last night...</td>\n      <td>1021</td>\n    </tr>\n    <tr>\n      <th>1022</th>\n      <td>earth</td>\n      <td>LOC</td>\n      <td>“Maybe for your nextexperiment, you could stud...</td>\n      <td>1022</td>\n    </tr>\n    <tr>\n      <th>1023</th>\n      <td>New England</td>\n      <td>LOC</td>\n      <td>He lives in New England with his wife</td>\n      <td>1023</td>\n    </tr>\n  </tbody>\n</table>\n<p>1024 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "Data_Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(start_ent)\n",
    "start_frase=[]\n",
    "end_frase=[]\n",
    "\n",
    "for i in end_ent[::]:\n",
    "    z=i\n",
    "    \n",
    "    while z<len(Book):\n",
    "        if Book[z]==\".\":\n",
    "            #print(\"finish aqui\", z, i)\n",
    "            end_frase.append(z)\n",
    "            break\n",
    "        else:\n",
    "            z+=1\n",
    "    \n",
    "for x in start_ent[::]:\n",
    "    f=x\n",
    "    while f>=0:\n",
    "        if Book[f]==\".\":\n",
    "            \n",
    "            start_frase.append(f)\n",
    "            #print(\"start aqui\", f,x)\n",
    "            break\n",
    "        else:\n",
    "            f-=1\n",
    "            if f<0:\n",
    "                Null=None\n",
    "                start_frase.append(Null)\n",
    "            #print(f)\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "start_ent[0:10], end_ent[0:10], start_frase[0:10], end_frase[0:10]\n",
    "len(start_frase), len(end_frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "Frases_Book=[]\n",
    "z=0\n",
    "for i in start_frase:\n",
    "    Frases_clean=re.sub('\\n |  |\\. ', '', (Book[start_frase[z]:end_frase[z]]))\n",
    "    \n",
    "    Frases_Book.append(Frases_clean)\n",
    "    z+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('New York',\n",
       " 'Also by Dan Brown \\nDigital FortressA N G E L S \\n&D E M O N SD A NB R O W N POCKET BOOKS\\nNew York London Toronto Sydney Singapore\\nh \\nT is book is a work of fiction',\n",
       " 192,\n",
       " 200,\n",
       " None,\n",
       " 284)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# print(Book[3936:4101])\n",
    "# (Book[start_frase[0]: end_frase[0]])\n",
    "i=0\n",
    "lugares[i],Frases_Book[i], start_ent[i], end_ent[i], start_frase[i], end_frase[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 lugares labels  \\\n",
       "0               New York    GPE   \n",
       "1                 Avenue    FAC   \n",
       "2               Americas    LOC   \n",
       "3               New York    GPE   \n",
       "4                     NY    GPE   \n",
       "...                  ...    ...   \n",
       "1019        Vatican City    GPE   \n",
       "1020             Vatican    FAC   \n",
       "1021  St. Peter’s Square    GPE   \n",
       "1022               earth    LOC   \n",
       "1023         New England    LOC   \n",
       "\n",
       "                                                 Quotes  Position  \n",
       "0     Also by Dan Brown \\nDigital FortressA N G E L ...         0  \n",
       "1     1230 Avenue of the Americas, New York, NY 1002...         1  \n",
       "2     1230 Avenue of the Americas, New York, NY 1002...         2  \n",
       "3     1230 Avenue of the Americas, New York, NY 1002...         3  \n",
       "4     1230 Avenue of the Americas, New York, NY 1002...         4  \n",
       "...                                                 ...       ...  \n",
       "1019  .”\\nLangdon felt a sudden anxiety, wondering i...      1019  \n",
       "1020   \\n“His Holiness asked me to give this to you,...      1020  \n",
       "1021  He and Vittoria had talked about it last night...      1021  \n",
       "1022  “Maybe for your nextexperiment, you could stud...      1022  \n",
       "1023              He lives in New England with his wife      1023  \n",
       "\n",
       "[1024 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lugares</th>\n      <th>labels</th>\n      <th>Quotes</th>\n      <th>Position</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>New York</td>\n      <td>GPE</td>\n      <td>Also by Dan Brown \\nDigital FortressA N G E L ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Avenue</td>\n      <td>FAC</td>\n      <td>1230 Avenue of the Americas, New York, NY 1002...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Americas</td>\n      <td>LOC</td>\n      <td>1230 Avenue of the Americas, New York, NY 1002...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New York</td>\n      <td>GPE</td>\n      <td>1230 Avenue of the Americas, New York, NY 1002...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NY</td>\n      <td>GPE</td>\n      <td>1230 Avenue of the Americas, New York, NY 1002...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1019</th>\n      <td>Vatican City</td>\n      <td>GPE</td>\n      <td>.”\\nLangdon felt a sudden anxiety, wondering i...</td>\n      <td>1019</td>\n    </tr>\n    <tr>\n      <th>1020</th>\n      <td>Vatican</td>\n      <td>FAC</td>\n      <td>\\n“His Holiness asked me to give this to you,...</td>\n      <td>1020</td>\n    </tr>\n    <tr>\n      <th>1021</th>\n      <td>St. Peter’s Square</td>\n      <td>GPE</td>\n      <td>He and Vittoria had talked about it last night...</td>\n      <td>1021</td>\n    </tr>\n    <tr>\n      <th>1022</th>\n      <td>earth</td>\n      <td>LOC</td>\n      <td>“Maybe for your nextexperiment, you could stud...</td>\n      <td>1022</td>\n    </tr>\n    <tr>\n      <th>1023</th>\n      <td>New England</td>\n      <td>LOC</td>\n      <td>He lives in New England with his wife</td>\n      <td>1023</td>\n    </tr>\n  </tbody>\n</table>\n<p>1024 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "Data_Book=pd.DataFrame(list(zip(lugares, label, Frases_Book)), columns=[\"lugares\",\"labels\", \"Quotes\"])\n",
    "Data_Book=pd.DataFrame(list(zip(lugares, label, Frases_Book, Data_Book.index)), columns=[\"lugares\",\"labels\", \"Quotes\", \"Position\"])\n",
    "Data_Book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frases_Book[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Book.to_csv(\"Data_Book_2.0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            lugares labels                                             Quotes  \\\n",
       "50           Louvre    LOC  Then again, his knowledge was limited to the s...   \n",
       "51         El Prado    FAC  Then again, his knowledge was limited to the s...   \n",
       "52             U.S.    GPE  Of course, the entire world is under the impre...   \n",
       "53          Frisbee    FAC  As if to accentuate the collegiate atmosphere,...   \n",
       "54  Fourth Symphony    FAC  As if to accentuate the collegiate atmosphere,...   \n",
       "\n",
       "    Position  \n",
       "50        50  \n",
       "51        51  \n",
       "52        52  \n",
       "53        53  \n",
       "54        54  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lugares</th>\n      <th>labels</th>\n      <th>Quotes</th>\n      <th>Position</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>50</th>\n      <td>Louvre</td>\n      <td>LOC</td>\n      <td>Then again, his knowledge was limited to the s...</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>El Prado</td>\n      <td>FAC</td>\n      <td>Then again, his knowledge was limited to the s...</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>U.S.</td>\n      <td>GPE</td>\n      <td>Of course, the entire world is under the impre...</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>Frisbee</td>\n      <td>FAC</td>\n      <td>As if to accentuate the collegiate atmosphere,...</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>Fourth Symphony</td>\n      <td>FAC</td>\n      <td>As if to accentuate the collegiate atmosphere,...</td>\n      <td>54</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "Data_Book[50:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "import googlemaps\n",
    "\n",
    "\n",
    "def coordinates(lugares):\n",
    "    #lugares_load=np.load(lugares)\n",
    "    #lugares_Book=pandas.read_csv(Data_Book)\n",
    "    pos, lugares_load= np.unique(lugares, return_index=True)\n",
    "    g_key=googlemaps.Client(key=\"AIzaSyAJ0DKhauX591z08eBbYxtcVjbFOZLfd2I\")\n",
    "    lugares_DF=pd.DataFrame({\"Position\": pos, \"lugares\":lugares_load})\n",
    "    lugares_DF[\"LAT_google\"]= None\n",
    "    lugares_DF[\"LON_google\"]= None\n",
    "    print (\"Launching Google API...\")\n",
    "    for i in range(0, len(lugares_DF), 1):\n",
    "        geocode_result=g_key.geocode(lugares_DF.iat[i,0])\n",
    "        try:\n",
    "            print (\"coordinates: \", i, \" of \", len(lugares_DF), \"extracted\")\n",
    "            lat=geocode_result[0][\"geometry\"][\"location\"][\"lat\"]\n",
    "            lon=geocode_result[0][\"geometry\"][\"location\"][\"lng\"]\n",
    "            lugares_DF.iat[i,lugares_DF.columns.get_loc(\"LAT_google\")]=lat\n",
    "            lugares_DF.iat[i,lugares_DF.columns.get_loc(\"LON_google\")]=lon\n",
    "        except:\n",
    "            lat=None\n",
    "            lon=None\n",
    "    print (\"coordinates: \", i, \" extracted\")\n",
    "    #lugares_DF.to_csv(r'lugares.csv', index = True)\n",
    "    return(lugares_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Launching Google API...\n",
      "coordinates:  0  of  240 extracted\n",
      "coordinates:  1  of  240 extracted\n",
      "coordinates:  2  of  240 extracted\n",
      "coordinates:  3  of  240 extracted\n",
      "coordinates:  4  of  240 extracted\n",
      "coordinates:  5  of  240 extracted\n",
      "coordinates:  6  of  240 extracted\n",
      "coordinates:  7  of  240 extracted\n",
      "coordinates:  8  of  240 extracted\n",
      "coordinates:  9  of  240 extracted\n",
      "coordinates:  10  of  240 extracted\n",
      "coordinates:  11  of  240 extracted\n",
      "coordinates:  12  of  240 extracted\n",
      "coordinates:  13  of  240 extracted\n",
      "coordinates:  14  of  240 extracted\n",
      "coordinates:  15  of  240 extracted\n",
      "coordinates:  16  of  240 extracted\n",
      "coordinates:  17  of  240 extracted\n",
      "coordinates:  18  of  240 extracted\n",
      "coordinates:  19  of  240 extracted\n",
      "coordinates:  20  of  240 extracted\n",
      "coordinates:  21  of  240 extracted\n",
      "coordinates:  22  of  240 extracted\n",
      "coordinates:  23  of  240 extracted\n",
      "coordinates:  24  of  240 extracted\n",
      "coordinates:  25  of  240 extracted\n",
      "coordinates:  26  of  240 extracted\n",
      "coordinates:  27  of  240 extracted\n",
      "coordinates:  28  of  240 extracted\n",
      "coordinates:  29  of  240 extracted\n",
      "coordinates:  30  of  240 extracted\n",
      "coordinates:  31  of  240 extracted\n",
      "coordinates:  32  of  240 extracted\n",
      "coordinates:  33  of  240 extracted\n",
      "coordinates:  34  of  240 extracted\n",
      "coordinates:  35  of  240 extracted\n",
      "coordinates:  36  of  240 extracted\n",
      "coordinates:  37  of  240 extracted\n",
      "coordinates:  38  of  240 extracted\n",
      "coordinates:  39  of  240 extracted\n",
      "coordinates:  40  of  240 extracted\n",
      "coordinates:  41  of  240 extracted\n",
      "coordinates:  42  of  240 extracted\n",
      "coordinates:  43  of  240 extracted\n",
      "coordinates:  44  of  240 extracted\n",
      "coordinates:  45  of  240 extracted\n",
      "coordinates:  46  of  240 extracted\n",
      "coordinates:  47  of  240 extracted\n",
      "coordinates:  48  of  240 extracted\n",
      "coordinates:  49  of  240 extracted\n",
      "coordinates:  50  of  240 extracted\n",
      "coordinates:  51  of  240 extracted\n",
      "coordinates:  52  of  240 extracted\n",
      "coordinates:  53  of  240 extracted\n",
      "coordinates:  54  of  240 extracted\n",
      "coordinates:  55  of  240 extracted\n",
      "coordinates:  56  of  240 extracted\n",
      "coordinates:  57  of  240 extracted\n",
      "coordinates:  58  of  240 extracted\n",
      "coordinates:  59  of  240 extracted\n",
      "coordinates:  60  of  240 extracted\n",
      "coordinates:  61  of  240 extracted\n",
      "coordinates:  62  of  240 extracted\n",
      "coordinates:  63  of  240 extracted\n",
      "coordinates:  64  of  240 extracted\n",
      "coordinates:  65  of  240 extracted\n",
      "coordinates:  66  of  240 extracted\n",
      "coordinates:  67  of  240 extracted\n",
      "coordinates:  68  of  240 extracted\n",
      "coordinates:  69  of  240 extracted\n",
      "coordinates:  70  of  240 extracted\n",
      "coordinates:  71  of  240 extracted\n",
      "coordinates:  72  of  240 extracted\n",
      "coordinates:  73  of  240 extracted\n",
      "coordinates:  74  of  240 extracted\n",
      "coordinates:  75  of  240 extracted\n",
      "coordinates:  76  of  240 extracted\n",
      "coordinates:  77  of  240 extracted\n",
      "coordinates:  78  of  240 extracted\n",
      "coordinates:  79  of  240 extracted\n",
      "coordinates:  80  of  240 extracted\n",
      "coordinates:  81  of  240 extracted\n",
      "coordinates:  82  of  240 extracted\n",
      "coordinates:  83  of  240 extracted\n",
      "coordinates:  84  of  240 extracted\n",
      "coordinates:  85  of  240 extracted\n",
      "coordinates:  86  of  240 extracted\n",
      "coordinates:  87  of  240 extracted\n",
      "coordinates:  88  of  240 extracted\n",
      "coordinates:  89  of  240 extracted\n",
      "coordinates:  90  of  240 extracted\n",
      "coordinates:  91  of  240 extracted\n",
      "coordinates:  92  of  240 extracted\n",
      "coordinates:  93  of  240 extracted\n",
      "coordinates:  94  of  240 extracted\n",
      "coordinates:  95  of  240 extracted\n",
      "coordinates:  96  of  240 extracted\n",
      "coordinates:  97  of  240 extracted\n",
      "coordinates:  98  of  240 extracted\n",
      "coordinates:  99  of  240 extracted\n",
      "coordinates:  100  of  240 extracted\n",
      "coordinates:  101  of  240 extracted\n",
      "coordinates:  102  of  240 extracted\n",
      "coordinates:  103  of  240 extracted\n",
      "coordinates:  104  of  240 extracted\n",
      "coordinates:  105  of  240 extracted\n",
      "coordinates:  106  of  240 extracted\n",
      "coordinates:  107  of  240 extracted\n",
      "coordinates:  108  of  240 extracted\n",
      "coordinates:  109  of  240 extracted\n",
      "coordinates:  110  of  240 extracted\n",
      "coordinates:  111  of  240 extracted\n",
      "coordinates:  112  of  240 extracted\n",
      "coordinates:  113  of  240 extracted\n",
      "coordinates:  114  of  240 extracted\n",
      "coordinates:  115  of  240 extracted\n",
      "coordinates:  116  of  240 extracted\n",
      "coordinates:  117  of  240 extracted\n",
      "coordinates:  118  of  240 extracted\n",
      "coordinates:  119  of  240 extracted\n",
      "coordinates:  120  of  240 extracted\n",
      "coordinates:  121  of  240 extracted\n",
      "coordinates:  122  of  240 extracted\n",
      "coordinates:  123  of  240 extracted\n",
      "coordinates:  124  of  240 extracted\n",
      "coordinates:  125  of  240 extracted\n",
      "coordinates:  126  of  240 extracted\n",
      "coordinates:  127  of  240 extracted\n",
      "coordinates:  128  of  240 extracted\n",
      "coordinates:  129  of  240 extracted\n",
      "coordinates:  130  of  240 extracted\n",
      "coordinates:  131  of  240 extracted\n",
      "coordinates:  132  of  240 extracted\n",
      "coordinates:  133  of  240 extracted\n",
      "coordinates:  134  of  240 extracted\n",
      "coordinates:  135  of  240 extracted\n",
      "coordinates:  136  of  240 extracted\n",
      "coordinates:  137  of  240 extracted\n",
      "coordinates:  138  of  240 extracted\n",
      "coordinates:  139  of  240 extracted\n",
      "coordinates:  140  of  240 extracted\n",
      "coordinates:  141  of  240 extracted\n",
      "coordinates:  142  of  240 extracted\n",
      "coordinates:  143  of  240 extracted\n",
      "coordinates:  144  of  240 extracted\n",
      "coordinates:  145  of  240 extracted\n",
      "coordinates:  146  of  240 extracted\n",
      "coordinates:  147  of  240 extracted\n",
      "coordinates:  148  of  240 extracted\n",
      "coordinates:  149  of  240 extracted\n",
      "coordinates:  150  of  240 extracted\n",
      "coordinates:  151  of  240 extracted\n",
      "coordinates:  152  of  240 extracted\n",
      "coordinates:  153  of  240 extracted\n",
      "coordinates:  154  of  240 extracted\n",
      "coordinates:  155  of  240 extracted\n",
      "coordinates:  156  of  240 extracted\n",
      "coordinates:  157  of  240 extracted\n",
      "coordinates:  158  of  240 extracted\n",
      "coordinates:  159  of  240 extracted\n",
      "coordinates:  160  of  240 extracted\n",
      "coordinates:  161  of  240 extracted\n",
      "coordinates:  162  of  240 extracted\n",
      "coordinates:  163  of  240 extracted\n",
      "coordinates:  164  of  240 extracted\n",
      "coordinates:  165  of  240 extracted\n",
      "coordinates:  166  of  240 extracted\n",
      "coordinates:  167  of  240 extracted\n",
      "coordinates:  168  of  240 extracted\n",
      "coordinates:  169  of  240 extracted\n",
      "coordinates:  170  of  240 extracted\n",
      "coordinates:  171  of  240 extracted\n",
      "coordinates:  172  of  240 extracted\n",
      "coordinates:  173  of  240 extracted\n",
      "coordinates:  174  of  240 extracted\n",
      "coordinates:  175  of  240 extracted\n",
      "coordinates:  176  of  240 extracted\n",
      "coordinates:  177  of  240 extracted\n",
      "coordinates:  178  of  240 extracted\n",
      "coordinates:  179  of  240 extracted\n",
      "coordinates:  180  of  240 extracted\n",
      "coordinates:  181  of  240 extracted\n",
      "coordinates:  182  of  240 extracted\n",
      "coordinates:  183  of  240 extracted\n",
      "coordinates:  184  of  240 extracted\n",
      "coordinates:  185  of  240 extracted\n",
      "coordinates:  186  of  240 extracted\n",
      "coordinates:  187  of  240 extracted\n",
      "coordinates:  188  of  240 extracted\n",
      "coordinates:  189  of  240 extracted\n",
      "coordinates:  190  of  240 extracted\n",
      "coordinates:  191  of  240 extracted\n",
      "coordinates:  192  of  240 extracted\n",
      "coordinates:  193  of  240 extracted\n",
      "coordinates:  194  of  240 extracted\n",
      "coordinates:  195  of  240 extracted\n",
      "coordinates:  196  of  240 extracted\n",
      "coordinates:  197  of  240 extracted\n",
      "coordinates:  198  of  240 extracted\n",
      "coordinates:  199  of  240 extracted\n",
      "coordinates:  200  of  240 extracted\n",
      "coordinates:  201  of  240 extracted\n",
      "coordinates:  202  of  240 extracted\n",
      "coordinates:  203  of  240 extracted\n",
      "coordinates:  204  of  240 extracted\n",
      "coordinates:  205  of  240 extracted\n",
      "coordinates:  206  of  240 extracted\n",
      "coordinates:  207  of  240 extracted\n",
      "coordinates:  208  of  240 extracted\n",
      "coordinates:  209  of  240 extracted\n",
      "coordinates:  210  of  240 extracted\n",
      "coordinates:  211  of  240 extracted\n",
      "coordinates:  212  of  240 extracted\n",
      "coordinates:  213  of  240 extracted\n",
      "coordinates:  214  of  240 extracted\n",
      "coordinates:  215  of  240 extracted\n",
      "coordinates:  216  of  240 extracted\n",
      "coordinates:  217  of  240 extracted\n",
      "coordinates:  218  of  240 extracted\n",
      "coordinates:  219  of  240 extracted\n",
      "coordinates:  220  of  240 extracted\n",
      "coordinates:  221  of  240 extracted\n",
      "coordinates:  222  of  240 extracted\n",
      "coordinates:  223  of  240 extracted\n",
      "coordinates:  224  of  240 extracted\n",
      "coordinates:  225  of  240 extracted\n",
      "coordinates:  226  of  240 extracted\n",
      "coordinates:  227  of  240 extracted\n",
      "coordinates:  228  of  240 extracted\n",
      "coordinates:  229  of  240 extracted\n",
      "coordinates:  230  of  240 extracted\n",
      "coordinates:  231  of  240 extracted\n",
      "coordinates:  232  of  240 extracted\n",
      "coordinates:  233  of  240 extracted\n",
      "coordinates:  234  of  240 extracted\n",
      "coordinates:  235  of  240 extracted\n",
      "coordinates:  236  of  240 extracted\n",
      "coordinates:  237  of  240 extracted\n",
      "coordinates:  238  of  240 extracted\n",
      "coordinates:  239  of  240 extracted\n",
      "coordinates:  239  extracted\n"
     ]
    }
   ],
   "source": [
    "lugares_DF=coordinates(lugares)\n",
    "# Data_Book_all=[Data_Book, lugares_DF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 lugares LAT_google LON_google\n",
       "0            1230 Avenue    40.6064   -73.9606\n",
       "1                   Abru    32.1797    51.4546\n",
       "2                 Aegean    39.0192    25.2686\n",
       "3              Alpha Rom    42.6557     -83.23\n",
       "4                America    37.0902   -95.7129\n",
       "..                   ...        ...        ...\n",
       "235  the mome e  \\n \\nnt    36.1533   -95.4985\n",
       "236    this Chigi Chapel    41.9115    12.4765\n",
       "237               transm    39.9295   -91.3998\n",
       "238                 twen    38.8039   -77.1174\n",
       "239            und \\n \\n    47.9229   -97.0768\n",
       "\n",
       "[240 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lugares</th>\n      <th>LAT_google</th>\n      <th>LON_google</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1230 Avenue</td>\n      <td>40.6064</td>\n      <td>-73.9606</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abru</td>\n      <td>32.1797</td>\n      <td>51.4546</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aegean</td>\n      <td>39.0192</td>\n      <td>25.2686</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alpha Rom</td>\n      <td>42.6557</td>\n      <td>-83.23</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>America</td>\n      <td>37.0902</td>\n      <td>-95.7129</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>the mome e  \\n \\nnt</td>\n      <td>36.1533</td>\n      <td>-95.4985</td>\n    </tr>\n    <tr>\n      <th>236</th>\n      <td>this Chigi Chapel</td>\n      <td>41.9115</td>\n      <td>12.4765</td>\n    </tr>\n    <tr>\n      <th>237</th>\n      <td>transm</td>\n      <td>39.9295</td>\n      <td>-91.3998</td>\n    </tr>\n    <tr>\n      <th>238</th>\n      <td>twen</td>\n      <td>38.8039</td>\n      <td>-77.1174</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>und \\n \\n</td>\n      <td>47.9229</td>\n      <td>-97.0768</td>\n    </tr>\n  </tbody>\n</table>\n<p>240 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "lugares_DF=lugares_DF.rename(columns={\"Position\": \"lugares\", \"lugares\": \"Position\"})\n",
    "lugares_DF=lugares_DF.drop(['Position'], axis=1)\n",
    "lugares_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_coord(lugares_DF, Data_Book, Book_name):  \n",
    "    lugares_DF=lugares_DF.rename(columns={\"Position\": \"lugares\", \"lugares\": \"Position\"})\n",
    "    lugares_DF=lugares_DF.drop(['Position'], axis=1)\n",
    "    Data_Book_2=pd.merge(lugares_DF, Data_Book, on = \"lugares\", sort = False)\n",
    "    Data_Book_2=Data_Book_2.sort_values(\"Position\")\n",
    "    Data_Book_2.to_csv(\"Data/Geocode_\" + Book_name + \".csv\")\n",
    "    print(\"saved Data_Book_Geocode.csv\")\n",
    "    return(Data_Book_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "saved Data_Book_Geocode.csv\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                lugares LAT_google LON_google labels  \\\n",
       "224            New York    40.7128    -74.006    GPE   \n",
       "8                Avenue    40.7494   -74.0033    FAC   \n",
       "6              Americas     54.526   -105.255    LOC   \n",
       "225            New York    40.7128    -74.006    GPE   \n",
       "210                  NY    40.7128    -74.006    GPE   \n",
       "..                  ...        ...        ...    ...   \n",
       "820        Vatican City    41.9029    12.4534    GPE   \n",
       "719             Vatican    41.9029    12.4534    FAC   \n",
       "506  St. Peter’s Square    41.9022    12.4567    GPE   \n",
       "898               earth    37.2321   -95.7243    LOC   \n",
       "220         New England    43.9654   -70.8227    LOC   \n",
       "\n",
       "                                                Quotes  Position  \n",
       "224  Also by Dan Brown \\nDigital FortressA N G E L ...         0  \n",
       "8    1230 Avenue of the Americas, New York, NY 1002...         1  \n",
       "6    1230 Avenue of the Americas, New York, NY 1002...         2  \n",
       "225  1230 Avenue of the Americas, New York, NY 1002...         3  \n",
       "210  1230 Avenue of the Americas, New York, NY 1002...         4  \n",
       "..                                                 ...       ...  \n",
       "820  .”\\nLangdon felt a sudden anxiety, wondering i...      1019  \n",
       "719   \\n“His Holiness asked me to give this to you,...      1020  \n",
       "506  He and Vittoria had talked about it last night...      1021  \n",
       "898  “Maybe for your nextexperiment, you could stud...      1022  \n",
       "220              He lives in New England with his wife      1023  \n",
       "\n",
       "[1024 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lugares</th>\n      <th>LAT_google</th>\n      <th>LON_google</th>\n      <th>labels</th>\n      <th>Quotes</th>\n      <th>Position</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>224</th>\n      <td>New York</td>\n      <td>40.7128</td>\n      <td>-74.006</td>\n      <td>GPE</td>\n      <td>Also by Dan Brown \\nDigital FortressA N G E L ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Avenue</td>\n      <td>40.7494</td>\n      <td>-74.0033</td>\n      <td>FAC</td>\n      <td>1230 Avenue of the Americas, New York, NY 1002...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Americas</td>\n      <td>54.526</td>\n      <td>-105.255</td>\n      <td>LOC</td>\n      <td>1230 Avenue of the Americas, New York, NY 1002...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>225</th>\n      <td>New York</td>\n      <td>40.7128</td>\n      <td>-74.006</td>\n      <td>GPE</td>\n      <td>1230 Avenue of the Americas, New York, NY 1002...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>210</th>\n      <td>NY</td>\n      <td>40.7128</td>\n      <td>-74.006</td>\n      <td>GPE</td>\n      <td>1230 Avenue of the Americas, New York, NY 1002...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>820</th>\n      <td>Vatican City</td>\n      <td>41.9029</td>\n      <td>12.4534</td>\n      <td>GPE</td>\n      <td>.”\\nLangdon felt a sudden anxiety, wondering i...</td>\n      <td>1019</td>\n    </tr>\n    <tr>\n      <th>719</th>\n      <td>Vatican</td>\n      <td>41.9029</td>\n      <td>12.4534</td>\n      <td>FAC</td>\n      <td>\\n“His Holiness asked me to give this to you,...</td>\n      <td>1020</td>\n    </tr>\n    <tr>\n      <th>506</th>\n      <td>St. Peter’s Square</td>\n      <td>41.9022</td>\n      <td>12.4567</td>\n      <td>GPE</td>\n      <td>He and Vittoria had talked about it last night...</td>\n      <td>1021</td>\n    </tr>\n    <tr>\n      <th>898</th>\n      <td>earth</td>\n      <td>37.2321</td>\n      <td>-95.7243</td>\n      <td>LOC</td>\n      <td>“Maybe for your nextexperiment, you could stud...</td>\n      <td>1022</td>\n    </tr>\n    <tr>\n      <th>220</th>\n      <td>New England</td>\n      <td>43.9654</td>\n      <td>-70.8227</td>\n      <td>LOC</td>\n      <td>He lives in New England with his wife</td>\n      <td>1023</td>\n    </tr>\n  </tbody>\n</table>\n<p>1024 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "Data_coord(lugares_DF, Data_Book, \"sss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ce97d3f43663>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mData_Book_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlugares_DF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mData_Book\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"lugares\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData_Book\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mData_Book_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     )\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# to avoid incompat dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;31m# If argument passed to validate,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1144\u001b[0m                     \u001b[0minferred_right\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minferred_left\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                 ):\n\u001b[1;32m-> 1146\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m             \u001b[1;31m# datetimelikes must match exactly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "Data_Book_2=pd.merge(lugares_DF, Data_Book, on = \"lugares\", sort = False)\n",
    "len(Data_Book)\n",
    "Data_Book_2.head(20)\n",
    "Data_Book_2=Data_Book_2.sort_values(\"Position\")\n",
    "Data_Book_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Data_Book_all.to_csv(\"Data_Book.csv\")\n",
    "# Data_Book[\"lugares\"][0]\n",
    "# lugares_unique=np.unique(lugares, return_index=True)\n",
    "# len(lugares_unique[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geolocator = Nominatim(user_agent=\"Travel-app\")\n",
    "# location = geolocator.geocode(Data_Book[\"lugares\"][1])\n",
    "# #print(location.address)\n",
    "# print((location.address))\n",
    "# print((location.latitude, location.longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# #Data_Book_short=Data_Book\n",
    "# #fff=Data_Book_short.drop_duplicates(subset =\"lugares\")\n",
    "\n",
    "\n",
    "# def coordinates_geopy(lugares):\n",
    "#     #lugares_load=np.load(lugares)\n",
    "#     #lugares_Book=pandas.read_csv(Data_Book)\n",
    "#     #Data_Book_short=Data_Book\n",
    "#     #fff=Data_Book_short.drop_duplicates(subset =\"lugares\")  \n",
    "#     lat=[]\n",
    "#     lon=[]\n",
    "#     lugares_unique=np.unique(lugares, return_index=True)\n",
    "#     address=[]\n",
    "\n",
    "#     #g_key=googlemaps.Client(key=\"AIzaSyAJ0DKhauX591z08eBbYxtcVjbFOZLfd2I\")\n",
    "#     geolocator = Nominatim(user_agent=\"Travel-app\")\n",
    "#     #lugares_DF=pd.DataFrame(lugares)\n",
    "#     # lugares_DF[\"LAT\"]= None\n",
    "#     # lugares_DF[\"LON\"]= None\n",
    "#     #print (\"Launching Google API...\")\n",
    "#     all_points=len(lugares_unique)\n",
    "#     start_time = time.time()\n",
    "#     for i in range(0, all_points, 1):\n",
    "#         #geocode_result=g_key.geocode(lugares_DF.iat[i,0])\n",
    "        \n",
    "#         location = geolocator.geocode(lugares_unique[i])\n",
    "#         if location is None:\n",
    "#             print(i, \" NONE \")\n",
    "#         else:\n",
    "#             lat.append(location.latitude)\n",
    "#             lon.append(location.longitude)\n",
    "#             address.append(location.address)\n",
    "#         # except:\n",
    "#         #     lat=None\n",
    "#         #     lon=None\n",
    "#         #print (\"coordinates: \", i, \"of \", all_points, \" extracted\", sep=' ', end='', flush=True)\n",
    "#             #print (i, sep=' ', end='', flush=False)\n",
    "#     #lugares_DF.to_csv(r'lugares.csv', index = True)\n",
    "#     print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#     return(lugares_unique, lon, lat, address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data_Book_Short=pd.DataFrame(list(zip(lugares_unique, lon, lat, address)), columns=[\"lugares\",\"LON\", \"LAT\", \"address\"])\n",
    "# Data_Book_Short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Book_2.to_csv(\"Data_Book_Geocode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Brown, Dan - Angels & Demons'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import os\n",
    "base=os.path.basename(\"C:\\\\Users\\\\aleja\\\\OneDrive\\\\Documents\\\\MBA\\\\99. Project Work\\\\Libros\\\\Brown, Dan - Angels & Demons.epub\")\n",
    "base\n",
    "os.path.splitext(base)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=ntpath.basename(\"C:\\\\Users\\\\aleja\\\\OneDrive\\\\Documents\\\\MBA\\\\99. Project Work\\\\Libros\\\\Brown, Dan - Angels & Demons.epub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Brown, Dan - Angels & Demons.epub'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}